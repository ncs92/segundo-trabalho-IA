{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.feature, skimage.io\n",
    "import numpy as np\n",
    "import math\n",
    "from math import floor\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from skimage.feature import hog\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#Pasta que contém o conjunto de dados já extraído.\n",
    "#Esta pasta contém as pastas A-Z e os arquivos NIST_Train_Upper.txt, NIST_Test_Upper.txt e NIST_Valid_Upper.txt\n",
    "NCharacter_dataset_folder = \"./exercicios/NCharacter_SD19_BMP/\"\n",
    "\n",
    "#Uma pasta onde as características extraídas são salvas.\n",
    "features_folder = 'features'\n",
    "\n",
    "\n",
    "\n",
    "#Classe que abstrai a divisão em zonas\n",
    "class Zonas(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #Função geradora que retorna uma zona de cada vez.\n",
    "    #Os argumentos são o número de linhas da imagem e o número de colunas da imagem.\n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        raise NotImplementedError\n",
    "\n",
    "#Classe que implementa a divisão em zonas retangulares.\n",
    "class ZonasRetangulares(Zonas):\n",
    "    \n",
    "    #Construtor que configura o zoneamento a ser feito: zonas_x zonas horizontais e zonas_y zonas verticais.\n",
    "    def __init__(self, zonas_x, zonas_y):\n",
    "        super(ZonasRetangulares, self).__init__()\n",
    "        self.zonas_x = zonas_x\n",
    "        self.zonas_y = zonas_y\n",
    "        \n",
    "    #Implementa a função geradora de zonas retangulares.\n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        cortes_x = np.floor(np.linspace(0, n_colunas, num=self.zonas_x+1)).astype(int)\n",
    "        cortes_y = np.floor(np.linspace(0, n_linhas, num=self.zonas_y+1)).astype(int)\n",
    "        #print (cortes_x)\n",
    "        #print (cortes_y)\n",
    "        for i in range(len(cortes_x)-1):\n",
    "            for j in range(len(cortes_y)-1):\n",
    "                yield(cortes_x[i], cortes_y[j], cortes_x[i+1], cortes_y[j+1],cortes_x[i] - cortes_x[i+1], cortes_y[i] - cortes_y[i+1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caraterísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma_cor(imagem):\n",
    "    #print('im', imagem.shape)\n",
    "    vals, counts = np.unique(imagem, return_counts=True)\n",
    "    o = vals.argsort()\n",
    "    vals = vals[o]\n",
    "    counts = counts[o]\n",
    "    if len(vals) < 2:\n",
    "        #imagem com apenas branco ou apenas preto\n",
    "        if vals[0] == 0:\n",
    "            return [counts[0], 0]\n",
    "        else:\n",
    "            return [0, counts[0]] \n",
    "    return counts\n",
    "\n",
    "def histograma_horizontal(imagem):\n",
    "    cortes = np.linspace(0, imagem.shape[0], 4)\n",
    "    j = imagem.shape[1]\n",
    "    hh = []\n",
    "    for m in range(0, len(cortes)-1): \n",
    "        qtdPreto = 0\n",
    "        qtdBranco = 0\n",
    "        for k in range(int(floor(cortes[m])), int(floor(cortes[m+1]))):            \n",
    "            for l in range(0, j):\n",
    "                if imagem[k][l] == 0:\n",
    "                    qtdPreto += 1\n",
    "                else:\n",
    "                    qtdBranco += 1\n",
    "        concatena = str(qtdBranco) + str(qtdPreto)\n",
    "        hh.append(int(concatena))\n",
    "    return hh\n",
    "        \n",
    "\n",
    "def histograma_vertical(imagem):\n",
    "    cortes = np.linspace(0, imagem.shape[1], 4)\n",
    "    j = imagem.shape[0]\n",
    "    hv = []\n",
    "    for m in range(0, len(cortes)-1): \n",
    "        qtdPreto = 0\n",
    "        qtdBranco = 0\n",
    "        for k in range(int(floor(cortes[m])), int(floor(cortes[m+1]))):            \n",
    "            for l in range(0, j):\n",
    "                if imagem[l][k] == 0:\n",
    "                    qtdPreto += 1\n",
    "                else:\n",
    "                    qtdBranco += 1\n",
    "        concatena = str(qtdBranco) + str(qtdPreto)\n",
    "        hv.append(int(concatena))\n",
    "    return hv\n",
    "\n",
    "def hog_image(image):\n",
    "    print(\"Hoggg\")\n",
    "    h = hog(image, orientations=4, pixels_per_cell=(2, 2), cells_per_block=(3, 3))\n",
    "    print(h)\n",
    "    return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraindo características de NIST_Train_Upper.txt\n",
      "extraindo características de NIST_Test_Upper.txt\n",
      "extraindo características de NIST_Valid_Upper.txt\n",
      "Fim da extração de características!\n"
     ]
    }
   ],
   "source": [
    "#Esta função apenas abre os arquivos com as listas de treino / teste e validação.\n",
    "#Retorna os caminhos para os arquivos, os rótulos e o nome dos arquivos sem o caminho.\n",
    "def parse_filelist(path, prefix=''):\n",
    "    with open(path, 'r') as f:\n",
    "        c = f.readlines()\n",
    "    caminhos = list(map(str.strip, c))\n",
    "    rotulos = [ i.split('/')[1].upper() for i in caminhos]\n",
    "    arquivos = [i.split('/')[-1] for i in caminhos]\n",
    "    p = zip(rotulos, arquivos)\n",
    "    caminhos = [ prefix + '/' + i[0] + '/' + i[1] for i in p]\n",
    "    \n",
    "    return list(zip(caminhos,rotulos, arquivos))\n",
    "\n",
    "#Esta é uma função que recebe o tipo de zoneamento a ser feito e as features que devem ser\n",
    "#extraídas de cada zona. Veja que essa função é chamada no \"for\" abaixo, que faz a extração das características\n",
    "#para cada uma das listas de imagens (treino, teste e validação)\n",
    "def extract_features(filelist, dataset_folder, zonas, features=[histograma_cor]):\n",
    "    instancias = parse_filelist(filelist, prefix=dataset_folder)\n",
    "    #Note que o MAP abaixo mapeia cada instância (imagem) à função que extrai as \n",
    "    #características (feature_extraction) abaixo.\n",
    "    features = list(map(feature_extraction, instancias, [zonas] * len(instancias), [features] * len(instancias)))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "#Essa função de extração das características de cada instância. zonas é uma instância de subclasse\n",
    "#de Zonas. Features é uma lista de funções que extraem características. Cada função da lista recebe uma matriz\n",
    "#que representa a imagem (que está na zona) e retorna o vetor de característica computado daquela característica. \n",
    "def feature_extraction(instancia, zonas, features):\n",
    "    caminho = instancia[0]\n",
    "    #print(instancia)\n",
    "    imagem = skimage.io.imread(caminho)\n",
    "    caracteristicas = np.array([])\n",
    "    #print(\"imagem.shape\",imagem.shape)\n",
    "    \n",
    "    res = []\n",
    "    for f in features:\n",
    "        for z in zonas.get_zonas(imagem.shape[1], imagem.shape[0]):\n",
    "            #print (\"%d:%d,%d:%d\" % (z[0], z[2], z[1], z[3]))\n",
    "            f_val = f(imagem[z[0]:z[2],z[1]:z[3]])\n",
    "            res.extend(f_val)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "#Realiza a extração das características!\n",
    "for i in [('NIST_Train_Upper.txt', 'train'), ('NIST_Test_Upper.txt', 'test'), ('NIST_Valid_Upper.txt', 'val')]:\n",
    "    print('extraindo características de %s' % (i[0]))\n",
    "    #note que esta linha extrai características de 4 zonas (2 imagens por linhas e 2 por coluna). \n",
    "    #Neste exemplo apenas a característica histograma_cor é computada.\n",
    "   # feats = extract_features(NCharacter_dataset_folder + i[0], NCharacter_dataset_folder, ZonasRetangulares(2,2), features=[histograma_cor])\n",
    "    feats = extract_features(NCharacter_dataset_folder + i[0], NCharacter_dataset_folder, ZonasRetangulares(4,4), features=[histograma_horizontal])\n",
    "    #Extraia aqui outras características! Escolha outros zoneamentos! (Só não esqueça de concatenar tudo em feats)\n",
    "    #Estude a função np.concatenate do numpy para concatenar!\n",
    "    \n",
    "    #np.save(open(features_folder + ('/%s_feats.pkl' % (i[1])), 'wb'), feats )\n",
    "    np.save(features_folder + ('/%s_feats.pkl' % (i[1])), feats)\n",
    "\n",
    "print('Fim da extração de características!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino e Teste com SVM e KNN (Sem validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elaine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redes neurais score:  0.121\n",
      "[[ 65  51   7  21   1   0  59   0   9   0   0   5  80  11  19   0  49  18\n",
      "   12   1  25   0  20   4   0   2]\n",
      " [ 61  32   6  12   4   0  39   0  10   0   0   3  79   3  10   0  62  21\n",
      "   13   0  29   0  47   3   0   1]\n",
      " [ 10   6  67   3  11   0   7   0  41   0   0  46   4   1  62   0   3  13\n",
      "  157   9   9   0   1  47   0  21]\n",
      " [ 19  30   1  24   1   0  27   0   3   0   0   2  89   8   5   0  86  12\n",
      "    9   0  22   0  57   0   0   1]\n",
      " [ 20   5  24   8  11   0   9   0  28   0   0  19  18   0  38   0  10  31\n",
      "   71   5  30   0   3  22   0  13]\n",
      " [ 23   8  23   2  15   0  14   0  37   0   0  27  20   2  64   0   7  39\n",
      "   63   4  36   0   1  26   0   8]\n",
      " [ 52  38   4  12   2   0  29   0   3   0   0   6  69   4  18   0  47  23\n",
      "   14   1  35   0  29   2   0   1]\n",
      " [ 41  33   3  20   4   0  28   0   2   0   0   5  87   4  14   0  74  18\n",
      "    8   0  18   0  41   2   0   0]\n",
      " [  2   1  21   0   3   0   0   0 441   0   0  68   0   0  13   0   0   2\n",
      "   22  56   1   0   0  24   0 161]\n",
      " [ 57  13  10   5   2   0  23   0 188   0   0  26  14   3   8   0   2   8\n",
      "   18   9   6   0   0  11   0  23]\n",
      " [ 22   8  27   3   7   0  11   0  57   0   0  24  19   0  45   0   4  23\n",
      "   55   4  19   0   8  16   0  25]\n",
      " [  5   1  66   1  13   0   5   0  70   0   0  61   5   0  35   0   2  12\n",
      "  106  15  12   0   2  45   0  40]\n",
      " [ 25  29   2   4   0   0  28   0   1   0   0   2  95   5   2   0 117   2\n",
      "    3   0   7   0 137   1   0   0]\n",
      " [ 22  32   2  17   0   0  23   0   5   0   0   3 104   6   3   0 105   5\n",
      "    6   1  15   0  87   1   0   2]\n",
      " [ 22  48   2  31   3   0  46   0   5   0   0   1 114  12  15   0  79  19\n",
      "    8   0  19   0  31   2   0   2]\n",
      " [ 51  29  12  10  11   0  30   0  11   0   0  10  47   4  49   0  24  61\n",
      "   42   0  53   0   8   8   0   7]\n",
      " [ 13  30   1  16   1   0  21   0   7   0   0   1  87   5  10   0 110  12\n",
      "    9   1  11   0 111   3   0   3]\n",
      " [ 57  20  14  12   2   0  20   0  41   0   0  21  29   5  44   0  18  34\n",
      "   47   1  40   0   8  17   0  16]\n",
      " [ 79  19  28  10   9   0  25   0  20   0   0  39  23   3  22   0   3  31\n",
      "   55   1  40   0   0  19   0  19]\n",
      " [  3   1   7   2   1   0   3   0 342   0   0  33   3   0   3   0   0   2\n",
      "    8   8   3   0   1  13   0  36]\n",
      " [ 26  41   8  23   3   0  36   0   5   0   0   4  79   6  20   0  84  17\n",
      "   11   1  30   0  59   2   0   3]\n",
      " [ 34  27  10  19   3   0  25   0  13   0   0  22  65   6  37   0  55  40\n",
      "   27   2  43   0  34  12   0   8]\n",
      " [  5   8   0   6   1   0   7   0   0   0   0   0  36   0   2   0 106   3\n",
      "    4   1   2   0 294   0   0   0]\n",
      " [  8   1  23   0   1   0   5   0 201   0   0  42   4   0  21   0   0  23\n",
      "   29  17  15   0   0  26   0  56]\n",
      " [ 28  17  31   5   3   0  25   0 100   0   0  25  30   5  26   0  25  22\n",
      "   32   3  32   0   6  17   0  21]\n",
      " [ 25   1  10   2   6   0  10   0 267   0   0  32   4   0  10   0   1   9\n",
      "   20  10  12   0   0  11   0  37]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A      0.084     0.142     0.105       459\n",
      "          B      0.060     0.074     0.066       435\n",
      "          C      0.164     0.129     0.145       518\n",
      "          D      0.090     0.061     0.072       396\n",
      "          E      0.093     0.030     0.046       365\n",
      "          F      0.000     0.000     0.000       419\n",
      "          G      0.052     0.075     0.061       389\n",
      "          H      0.000     0.000     0.000       402\n",
      "          I      0.231     0.541     0.324       815\n",
      "          J      0.000     0.000     0.000       426\n",
      "          K      0.000     0.000     0.000       377\n",
      "          L      0.116     0.123     0.119       496\n",
      "          M      0.079     0.207     0.114       460\n",
      "          N      0.065     0.014     0.023       439\n",
      "          O      0.025     0.033     0.028       459\n",
      "          P      0.000     0.000     0.000       467\n",
      "          Q      0.103     0.243     0.144       452\n",
      "          R      0.068     0.076     0.072       446\n",
      "          S      0.065     0.124     0.085       445\n",
      "          T      0.053     0.017     0.026       469\n",
      "          U      0.053     0.066     0.059       458\n",
      "          V      0.000     0.000     0.000       482\n",
      "          W      0.298     0.619     0.403       475\n",
      "          X      0.078     0.055     0.065       472\n",
      "          Y      0.000     0.000     0.000       453\n",
      "          Z      0.073     0.079     0.076       467\n",
      "\n",
      "avg / total      0.078     0.121     0.088     11941\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elaine\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.load(features_folder + '/train_feats.pkl.npy')\n",
    "train_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Train_Upper.txt')\n",
    "train_rotulos = [i[1] for i in train_rotulos]\n",
    "#print (len(train_rotulos), train_features.shape)\n",
    "\n",
    "valid_features = np.load(features_folder + '/val_feats.pkl.npy')\n",
    "valid_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Valid_Upper.txt')\n",
    "valid_rotulos = [i[1] for i in valid_rotulos]\n",
    "#print (len(test_rotulos), test_features.shape)\n",
    "\n",
    "test_features = np.load(features_folder + '/test_feats.pkl.npy')\n",
    "test_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Test_Upper.txt')\n",
    "test_rotulos = [i[1] for i in test_rotulos]\n",
    "#print (len(test_rotulos), test_features.shape)\n",
    "\n",
    "SS = StandardScaler()\n",
    "SS.fit(train_features)\n",
    "train_features = SS.transform(train_features)\n",
    "valid_features = SS.transform(valid_features)\n",
    "test_features = SS.transform(test_features)\n",
    "\n",
    "#KKKKKKKKKKKKKNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
    "n_knn = [1,3,5,7,9,13]\n",
    "melhor_porcentagem = 0.0\n",
    "melhor_k = 0\n",
    "for n in n_knn:\n",
    "    KNN = KNNC(n_neighbors=n, weights= 'distance', p = 1)\n",
    "    KNN.fit(train_features, train_rotulos)\n",
    "    v_pred = KNN.predict(valid_features)\n",
    "    porcentagem = accuracy_score(valid_rotulos, v_pred)\n",
    "    if porcentagem > melhor_porcentagem:\n",
    "        melhor_k = n\n",
    "        melhor_porcentagem = porcentagem\n",
    "    print(\"---------\")\n",
    "    print(porcentagem)\n",
    "\n",
    "print('KNN melhor porcentagem: ' , melhor_porcentagem)\n",
    "print('KNN melhor K: ', melhor_k)\n",
    "\n",
    "KNN = KNNC(n_neighbors=melhor_k, weights= 'distance', p = 1)\n",
    "KNN.fit(train_features, train_rotulos)\n",
    "y_pred = KNN.predict(test_features)\n",
    "\n",
    "print('KNN score: ' , '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "print(confusion_matrix(test_rotulos, y_pred))\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "#SSSSSSSSSSSVVVVVVVVVVVMMMMMMMMMMMMMMMM\n",
    "clf = SVC()\n",
    "clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(valid_features)\n",
    "y_pred = clf.predict(test_features)\n",
    "\n",
    "print('SVC score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "print(confusion_matrix(test_rotulos, y_pred))\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "####################################\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(valid_features)\n",
    "y_pred = clf.predict(test_features)\n",
    "\n",
    "print('LinearSVC score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "print(confusion_matrix(test_rotulos, y_pred))\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "##################################\n",
    "\n",
    "clf = NuSVC()\n",
    "clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(valid_features)\n",
    "y_pred = clf.predict(test_features)\n",
    "\n",
    "print('NuSVC score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "print(confusion_matrix(test_rotulos, y_pred))\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "#ARVORE DECISÃO\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(valid_features)\n",
    "y_pred = clf.predict(test_features)\n",
    "clf.predict_proba(test_features)\n",
    "\n",
    "print('Arvore de decisao score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "print(confusion_matrix(test_rotulos, y_pred))\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "#REDES NEURAIS\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(4, 1), random_state=1)\n",
    "clf = clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(valid_features)\n",
    "y_pred = clf.predict(test_features)\n",
    "clf.predict_proba(test_features)\n",
    "\n",
    "print('Redes neurais score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "print(confusion_matrix(test_rotulos, y_pred))\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
