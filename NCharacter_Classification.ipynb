{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.feature, skimage.io\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "#Pasta que contém o conjunto de dados já extraído.\n",
    "#Esta pasta contém as pastas A-Z e os arquivos NIST_Train_Upper.txt, NIST_Test_Upper.txt e NIST_Valid_Upper.txt\n",
    "NCharacter_dataset_folder = \"./exercicios/NCharacter_SD19_BMP/\"\n",
    "\n",
    "#Uma pasta onde as características extraídas são salvas.\n",
    "features_folder = 'features'\n",
    "\n",
    "#Classe que abstrai a divisão em zonas\n",
    "class Zonas(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #Função geradora que retorna uma zona de cada vez.\n",
    "    #Os argumentos são o número de linhas da imagem e o número de colunas da imagem.\n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        raise NotImplementedError\n",
    "\n",
    "#Classe que implementa a divisão em zonas retangulares.\n",
    "class ZonasRetangulares(Zonas):\n",
    "    \n",
    "    #Construtor que configura o zoneamento a ser feito: zonas_x zonas horizontais e zonas_y zonas verticais.\n",
    "    def __init__(self, zonas_x, zonas_y):\n",
    "        super(ZonasRetangulares, self).__init__()\n",
    "        self.zonas_x = zonas_x\n",
    "        self.zonas_y = zonas_y\n",
    "        \n",
    "    #Implementa a função geradora de zonas retangulares.\n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        cortes_x = np.floor(np.linspace(0, n_colunas, num=self.zonas_x+1)).astype(int)\n",
    "        cortes_y = np.floor(np.linspace(0, n_linhas, num=self.zonas_y+1)).astype(int)\n",
    "        #print (cortes_x)\n",
    "        #print (cortes_y)\n",
    "        for i in range(len(cortes_x)-1):\n",
    "            for j in range(len(cortes_y)-1):\n",
    "                yield(cortes_x[i], cortes_y[j], cortes_x[i+1], cortes_y[j+1],cortes_x[i] - cortes_x[i+1], cortes_y[i] - cortes_y[i+1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caraterísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma_cor(imagem):\n",
    "    #print('im', imagem.shape)\n",
    "    vals, counts = np.unique(imagem, return_counts=True)\n",
    "    o = vals.argsort()\n",
    "    vals = vals[o]\n",
    "    counts = counts[o]\n",
    "    if len(vals) < 2:\n",
    "        #imagem com apenas branco ou apenas preto\n",
    "        if vals[0] == 0:\n",
    "            return [counts[0], 0]\n",
    "        else:\n",
    "            return [0, counts[0]] \n",
    "    return counts\n",
    "\n",
    "def histograma_horizontal(imagem):\n",
    "    i = imagem.shape[0]\n",
    "    j = imagem.shape[1]\n",
    "    hh = []\n",
    "    for k in range(0, i):\n",
    "        qtdPreto = 0\n",
    "        qtdBranco = 0\n",
    "        for l in range(0, j):\n",
    "            if imagem[k][l] == 0:\n",
    "                qtdPreto += 1\n",
    "            else:\n",
    "                qtdBranco += 1\n",
    "        concatena = str(qtdBranco) + str(qtdPreto)\n",
    "        hh.append(int(concatena))\n",
    "    return hh\n",
    "        \n",
    "\n",
    "def histograma_vertical(imagem):\n",
    "    i = imagem.shape[0]\n",
    "    j = imagem.shape[1]\n",
    "    hv = []\n",
    "    for k in range(0, i):\n",
    "        qtdPreto = 0\n",
    "        qtdBranco = 0\n",
    "        for l in range(0, j):\n",
    "            if imagem[l][k] == 0:\n",
    "                qtdPreto += 1\n",
    "            else:\n",
    "                qtdBranco += 1\n",
    "        concatena = str(qtdBranco) + str(qtdPreto)\n",
    "        hv.append(int(concatena))\n",
    "    return hv\n",
    "\n",
    "def hog_image(image):\n",
    "    return hog(image, orientations=4, pixels_per_cell=(1, 1), cells_per_block=(1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraindo características de NIST_Train_Upper.txt\n",
      "extraindo características de NIST_Test_Upper.txt\n",
      "extraindo características de NIST_Valid_Upper.txt\n",
      "Fim da extração de características!\n"
     ]
    }
   ],
   "source": [
    "#Esta função apenas abre os arquivos com as listas de treino / teste e validação.\n",
    "#Retorna os caminhos para os arquivos, os rótulos e o nome dos arquivos sem o caminho.\n",
    "def parse_filelist(path, prefix=''):\n",
    "    with open(path, 'r') as f:\n",
    "        c = f.readlines()\n",
    "    caminhos = list(map(str.strip, c))\n",
    "    rotulos = [ i.split('/')[1].upper() for i in caminhos]\n",
    "    arquivos = [i.split('/')[-1] for i in caminhos]\n",
    "    p = zip(rotulos, arquivos)\n",
    "    caminhos = [ prefix + '/' + i[0] + '/' + i[1] for i in p]\n",
    "    \n",
    "    return list(zip(caminhos,rotulos, arquivos))\n",
    "\n",
    "#Esta é uma função que recebe o tipo de zoneamento a ser feito e as features que devem ser\n",
    "#extraídas de cada zona. Veja que essa função é chamada no \"for\" abaixo, que faz a extração das características\n",
    "#para cada uma das listas de imagens (treino, teste e validação)\n",
    "def extract_features(filelist, dataset_folder, zonas, features=[histograma_cor, histograma_vertical, histograma_horizontal, hog_image]):\n",
    "    instancias = parse_filelist(filelist, prefix=dataset_folder)\n",
    "    #Note que o MAP abaixo mapeia cada instância (imagem) à função que extrai as \n",
    "    #características (feature_extraction) abaixo.\n",
    "    features = list(map(feature_extraction, instancias, [zonas] * len(instancias), [features] * len(instancias)))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "#Essa função de extração das características de cada instância. zonas é uma instância de subclasse\n",
    "#de Zonas. Features é uma lista de funções que extraem características. Cada função da lista recebe uma matriz\n",
    "#que representa a imagem (que está na zona) e retorna o vetor de característica computado daquela característica. \n",
    "def feature_extraction(instancia, zonas, features):\n",
    "    caminho = instancia[0]\n",
    "    #print(instancia)\n",
    "    imagem = skimage.io.imread(caminho)\n",
    "    caracteristicas = np.array([])\n",
    "    #print(\"imagem.shape\",imagem.shape)\n",
    "    \n",
    "    res = []\n",
    "    for f in features:\n",
    "        for z in zonas.get_zonas(imagem.shape[1], imagem.shape[0]):\n",
    "            #print (\"%d:%d,%d:%d\" % (z[0], z[2], z[1], z[3]))\n",
    "            f_val = f(imagem[z[0]:z[2],z[1]:z[3]])\n",
    "            res.extend(f_val)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "#Realiza a extração das características!\n",
    "for i in [('NIST_Train_Upper.txt', 'train'), ('NIST_Test_Upper.txt', 'test'), ('NIST_Valid_Upper.txt', 'val')]:\n",
    "    print('extraindo características de %s' % (i[0]))\n",
    "    #note que esta linha extrai características de 4 zonas (2 imagens por linhas e 2 por coluna). \n",
    "    #Neste exemplo apenas a característica histograma_cor é computada.\n",
    "    feats = extract_features(NCharacter_dataset_folder + i[0], NCharacter_dataset_folder, ZonasRetangulares(2,2), features=[histograma_cor])\n",
    "    \n",
    "    #Extraia aqui outras características! Escolha outros zoneamentos! (Só não esqueça de concatenar tudo em feats)\n",
    "    #Estude a função np.concatenate do numpy para concatenar!\n",
    "    \n",
    "    #np.save(open(features_folder + ('/%s_feats.pkl' % (i[1])), 'wb'), feats )\n",
    "    np.save(features_folder + ('/%s_feats.pkl' % (i[1])), feats)\n",
    "\n",
    "print('Fim da extração de características!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino e Teste com SVM e KNN (Sem validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37440 (37440, 8)\n",
      "11941 (11941, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elaine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score:  0.273\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A      0.181     0.288     0.222       459\n",
      "          B      0.158     0.262     0.197       435\n",
      "          C      0.231     0.386     0.289       518\n",
      "          D      0.116     0.242     0.157       396\n",
      "          E      0.143     0.208     0.169       365\n",
      "          F      0.159     0.317     0.212       419\n",
      "          G      0.202     0.339     0.253       389\n",
      "          H      0.129     0.211     0.160       402\n",
      "          I      0.847     0.460     0.596       815\n",
      "          J      0.293     0.293     0.293       426\n",
      "          K      0.094     0.188     0.126       377\n",
      "          L      0.792     0.889     0.838       496\n",
      "          M      0.159     0.130     0.143       460\n",
      "          N      0.114     0.107     0.111       439\n",
      "          O      0.198     0.072     0.105       459\n",
      "          P      0.516     0.281     0.363       467\n",
      "          Q      0.305     0.254     0.277       452\n",
      "          R      0.142     0.034     0.054       446\n",
      "          S      0.334     0.283     0.307       445\n",
      "          T      0.639     0.714     0.675       469\n",
      "          U      0.240     0.094     0.135       458\n",
      "          V      0.360     0.131     0.192       482\n",
      "          W      0.462     0.179     0.258       475\n",
      "          X      0.154     0.085     0.109       472\n",
      "          Y      0.438     0.322     0.372       453\n",
      "          Z      0.182     0.081     0.112       467\n",
      "\n",
      "avg / total      0.316     0.273     0.274     11941\n",
      "\n",
      "SVM score:  0.333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A      0.511     0.207     0.295       459\n",
      "          B      0.244     0.269     0.256       435\n",
      "          C      0.300     0.284     0.292       518\n",
      "          D      0.140     0.104     0.119       396\n",
      "          E      0.189     0.208     0.198       365\n",
      "          F      0.230     0.265     0.246       419\n",
      "          G      0.296     0.398     0.340       389\n",
      "          H      0.181     0.177     0.179       402\n",
      "          I      0.961     0.425     0.589       815\n",
      "          J      0.388     0.448     0.416       426\n",
      "          K      0.122     0.422     0.189       377\n",
      "          L      0.784     0.954     0.861       496\n",
      "          M      0.253     0.313     0.280       460\n",
      "          N      0.215     0.100     0.137       439\n",
      "          O      0.257     0.124     0.167       459\n",
      "          P      0.531     0.383     0.445       467\n",
      "          Q      0.334     0.429     0.376       452\n",
      "          R      0.143     0.018     0.032       446\n",
      "          S      0.301     0.497     0.375       445\n",
      "          T      0.613     0.821     0.702       469\n",
      "          U      0.281     0.162     0.205       458\n",
      "          V      0.446     0.178     0.255       482\n",
      "          W      0.377     0.322     0.347       475\n",
      "          X      0.161     0.324     0.215       472\n",
      "          Y      0.445     0.501     0.471       453\n",
      "          Z      0.271     0.161     0.202       467\n",
      "\n",
      "avg / total      0.371     0.333     0.329     11941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features = np.load(features_folder + '/train_feats.pkl.npy')\n",
    "train_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Train_Upper.txt')\n",
    "train_rotulos = [i[1] for i in train_rotulos]\n",
    "print (len(train_rotulos), train_features.shape)\n",
    "\n",
    "test_features = np.load(features_folder + '/test_feats.pkl.npy')\n",
    "test_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Test_Upper.txt')\n",
    "test_rotulos = [i[1] for i in test_rotulos]\n",
    "print (len(test_rotulos), test_features.shape)\n",
    "\n",
    "SS = StandardScaler()\n",
    "SS.fit(train_features)\n",
    "train_features = SS.transform(train_features)\n",
    "test_features = SS.transform(test_features)\n",
    "\n",
    "#KKKKKKKKKKKKKNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
    "KNN = KNNC(n_neighbors=3)\n",
    "\n",
    "KNN.fit(train_features, train_rotulos)\n",
    "\n",
    "\n",
    "y_pred = KNN.predict(test_features)\n",
    "\n",
    "print('KNN score: ' , '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "#print(confusion_matrix(test_rotulos, y_pred))\n",
    "\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "#SSSSSSSSSSSVVVVVVVVVVVMMMMMMMMMMMMMMMM\n",
    "clf = SVC()\n",
    "clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(test_features)\n",
    "\n",
    "print('SVM score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "#print(confusion_matrix(test_rotulos, y_pred))\n",
    "\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "\n",
    "#ARVORE DECISÃO\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_rotulos)\n",
    "clf.predict(test_features)\n",
    "clf.predict_proba(test_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
